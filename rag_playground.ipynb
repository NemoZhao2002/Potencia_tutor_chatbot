{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting global variables(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in /Users/zjh/micromamba/envs/rag_env/lib/python3.9/site-packages (0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import logging\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.schema import Document\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core import Settings\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('API_KEY')\n",
    "\n",
    "VECTOR_STORAGE_DIR = \"./vector\"\n",
    "DATA_STORAGE_DIR = \"./data\"\n",
    "\n",
    "os.makedirs(DATA_STORAGE_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Tutor training handbook/Tutor training handbook.pdf\n",
      "Tutor training handbook.pdf\n",
      "./data/Pronouns and Prepositions/(Pronouns) Potencia - Lesson 3 - Nikita Goyal.docx\n",
      "(Pronouns) Potencia - Lesson 3 - Nikita Goyal.docx\n",
      "./data/Pronouns and Prepositions/(Pronouns_Prepositions) Class 6 - Amber Adelman.pptx\n",
      "(Pronouns_Prepositions) Class 6 - Amber Adelman.pptx\n",
      "./data/Pronouns and Prepositions/(Pronouns_Food) Class 5  - Amber Adelman.pdf\n",
      "(Pronouns_Food) Class 5  - Amber Adelman.pdf\n",
      "./data/Pronouns and Prepositions/(Prepositions_Verbs) Lesson 2 - Leila - Ashley Cornwell.pptx\n",
      "(Prepositions_Verbs) Lesson 2 - Leila - Ashley Cornwell.pptx\n",
      "./data/Pronouns and Prepositions/(Prepositions) - Paridhi Rathi.pptx\n",
      "(Prepositions) - Paridhi Rathi.pptx\n",
      "./data/Pronouns and Prepositions/(Preposition_Possession) Lesson #2 - Adriana Da Gama Henriques.pptx\n",
      "(Preposition_Possession) Lesson #2 - Adriana Da Gama Henriques.pptx\n",
      "./data/Pronouns and Prepositions/(Prepositions_Verbs) Lesson 3 - Leila - Ashley Cornwell.pptx\n",
      "(Prepositions_Verbs) Lesson 3 - Leila - Ashley Cornwell.pptx\n",
      "./data/Verbs/(Verbs Practice) Potencia Worksheet 1_Elaine - Shilpi Dey.docx\n",
      "(Verbs Practice) Potencia Worksheet 1_Elaine - Shilpi Dey.docx\n",
      "./data/Verbs/(Verbs) 5 Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "(Verbs) 5 Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "./data/Verbs/(Verbs) 2 To Be - Lara Creyghton.pptx\n",
      "(Verbs) 2 To Be - Lara Creyghton.pptx\n",
      "./data/Verbs/(Verbs) English Class #3 - Danielle Coan.pptx\n",
      "(Verbs) English Class #3 - Danielle Coan.pptx\n",
      "./data/Verbs/(Verbs) - Paridhi Rathi.pptx\n",
      "(Verbs) - Paridhi Rathi.pptx\n",
      "./data/Verbs/(Verbs) Lesson on irregular verbs - Dana.docx\n",
      "(Verbs) Lesson on irregular verbs - Dana.docx\n",
      "./data/Verbs/(Verbs_Citizenship Practice) Potencia Tutoring (1) - Nicole Page.docx\n",
      "(Verbs_Citizenship Practice) Potencia Tutoring (1) - Nicole Page.docx\n",
      "./data/Verbs/(Verbs) 10 Lesson with Nitieixan - Jakob Lattanzi.pptx\n",
      "(Verbs) 10 Lesson with Nitieixan - Jakob Lattanzi.pptx\n",
      "./data/Verbs/(Verb Tenses) Lesson #4   - Adriana Da Gama Henriques.pptx\n",
      "(Verb Tenses) Lesson #4   - Adriana Da Gama Henriques.pptx\n",
      "./data/Verbs/(Verbs) English Class #2 - Danielle Coan.pptx\n",
      "(Verbs) English Class #2 - Danielle Coan.pptx\n",
      "./data/Verbs/(Verbs) Lesson #3 - Adriana Da Gama Henriques.pptx\n",
      "(Verbs) Lesson #3 - Adriana Da Gama Henriques.pptx\n",
      "./data/Verbs/(Verbs) 16 Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "(Verbs) 16 Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "./data/Verbs/(Verbs) Potencia Tutoring - Nicole Page.docx\n",
      "(Verbs) Potencia Tutoring - Nicole Page.docx\n",
      "./data/Verbs/(Verbs) 2_to_be_by Sarah L.pptx.pptx\n",
      "(Verbs) 2_to_be_by Sarah L.pptx.pptx\n",
      "./data/Verbs/(Verbs_Basics) 23 Lesson Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "(Verbs_Basics) 23 Lesson Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "./data/Verbs/(Verbs) lesson #6 11.9.20 -- past simple of irregular verbs  - Moxie Thompson.png\n",
      "(Verbs) lesson #6 11.9.20 -- past simple of irregular verbs  - Moxie Thompson.png\n",
      "./data/Verbs/(Verbs) 1 Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "(Verbs) 1 Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "./data/Verbs/(Verbs_Prepositions) Class 7 - Amber Adelman.pdf\n",
      "(Verbs_Prepositions) Class 7 - Amber Adelman.pdf\n",
      "./data/Verbs/(Verb Tenses) - Paridhi Rathi.pptx\n",
      "(Verb Tenses) - Paridhi Rathi.pptx\n"
     ]
    }
   ],
   "source": [
    "def get_file_names_in_directory(directory_path):\n",
    "    \"\"\"List all files in the directory\"\"\"\n",
    "    file_paths = []\n",
    "    names = []\n",
    "    for dirpath, _, filenames in os.walk(directory_path):\n",
    "        for filename in filenames:\n",
    "            file_paths.append(os.path.join(dirpath, filename))\n",
    "            names.append(filename)\n",
    "    return file_paths, names\n",
    "\n",
    "# Get file paths and file names\n",
    "file_paths, file_names = get_file_names_in_directory(DATA_STORAGE_DIR)\n",
    "for file_path, file_name in zip(file_paths, file_names):\n",
    "    print(file_path)\n",
    "    print(file_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions for datapreprocessing\n",
    "- load_any_documents\n",
    "- load_pptx_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "import fitz\n",
    "def load_pptx_text(file_path):\n",
    "    \"\"\"Given a pptx file path, extract all the text from it\"\"\"\n",
    "    pres = Presentation(file_path)\n",
    "    pptx_text = []\n",
    "    for slide in pres.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                text_frame = shape.text_frame\n",
    "                for paragraph in text_frame.paragraphs:\n",
    "                    for run in paragraph.runs:\n",
    "                        pptx_text.append(run.text)\n",
    "                        \n",
    "    return pptx_text\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    \"\"\"Extract text from a PDF file using PyMuPDF.\"\"\"\n",
    "    text = []\n",
    "    try:\n",
    "        pdf_document = fitz.open(file_path)\n",
    "        for page_num in range(len(pdf_document)):\n",
    "            page = pdf_document[page_num]\n",
    "            text.append(page.get_text())\n",
    "        pdf_document.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF file {file_path}: {e}\")\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def load_any_documents(dirpath:str):\n",
    "    \"\"\"Given a directory path, load all the files in it: .pptx, .docx, .txt, .pdf, png\"\"\"\n",
    "    documents = []\n",
    "    for file_name in os.listdir(dirpath):\n",
    "        file_path = os.path.join(dirpath, file_name)\n",
    "        \n",
    "        if file_name.endswith(\".pptx\"):\n",
    "            # handle pptx file\n",
    "            pptx_text = load_pptx_text(file_path)\n",
    "            documents.append(Document(text=\"\\n\".join(pptx_text), doc_id=file_name))\n",
    "        elif file_name.endswith(\".pdf\"):\n",
    "            pdf_text = extract_text_from_pdf(file_path)\n",
    "            documents.append(Document(text=pdf_text, doc_id=file_name))\n",
    "        else:\n",
    "            documents += (SimpleDirectoryReader(input_files=[file_path]).load_data())\n",
    "            \n",
    "    return documents\n",
    "\n",
    "\n",
    "# documents = load_any_documents(\"./data/Verbs\")\n",
    "# for doc in documents:\n",
    "#     print(f\"{type(doc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data \n",
    "- read from desginated directory using SimpleDirectoryReader, returns a list of document objects. \n",
    "- docx, ppt, pdf file formats are all supported\n",
    "\n",
    "## Storage Context\n",
    "- represents the location for both **storing** and **loading** the index data\n",
    "- In this demo, each subdirectory is represented as an index\n",
    "  - We could explore other alternatives. \n",
    "\n",
    "```\n",
    "./vector/Verbs/\n",
    "├── Category1/\n",
    "│   ├── SubcategoryA/\n",
    "│   │   ├── file1.txt\n",
    "│   │   └── file2.txt\n",
    "│   └── SubcategoryB/\n",
    "│       └── file3.txt\n",
    "└── Category2/\n",
    "    └── file4.txt\n",
    "\n",
    "./data/Verbs/\n",
    "├── Category1/\n",
    "│   ├── SubcategoryA/       # Indexes for SubcategoryA files are stored here\n",
    "│   └── SubcategoryB/       # Indexes for SubcategoryB files are stored here\n",
    "└── Category2/              # Indexes for Category2 files are stored here\n",
    "```\n",
    "\n",
    "## Indexing\n",
    "- generates embedding for each document, using designated embedding model. \n",
    "- VectorStoreIndex.from_documents: generate index from document nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 00:44:04,421 [INFO] Loading all indices.\n",
      "2024-12-04 00:44:04,425 [INFO] Loaded existing index for subdirectory Tutor training handbook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutor training handbook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 00:44:05,391 [INFO] Loading all indices.\n",
      "2024-12-04 00:44:05,395 [INFO] Loaded existing index for subdirectory Pronouns and Prepositions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pronouns and Prepositions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 00:44:06,380 [INFO] Loading all indices.\n",
      "2024-12-04 00:44:06,383 [INFO] Loaded existing index for subdirectory Verbs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# initialize an index list\n",
    "index_list = []\n",
    "description_list = []\n",
    "## represent index represent a subdirectory\n",
    "for dirpath, _, file_names in os.walk(DATA_STORAGE_DIR):\n",
    "    if file_names:\n",
    "        relative_path = os.path.relpath(dirpath, DATA_STORAGE_DIR)\n",
    "        storage_dir = os.path.join(VECTOR_STORAGE_DIR, relative_path)\n",
    "        os.makedirs(storage_dir, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "            description = storage_dir.split('/')[-1]\n",
    "            print(description)\n",
    "            index_list.append(index)\n",
    "            description_list.append(description)\n",
    "            logger.info(f\"Loaded existing index for subdirectory {relative_path}.\")\n",
    "        except FileNotFoundError:\n",
    "            logger.info(f\"Index for {relative_path} not found. Creating a new index.\")\n",
    "            \n",
    "            # load all document in current subdirectory\n",
    "            documents = load_any_documents(dirpath)\n",
    "            # documents = [{\"id\": doc[\"id\"], \"content\": doc[\"content\"]} for doc in documents]\n",
    "            index = VectorStoreIndex.from_documents(documents)\n",
    "            index.storage_context.persist(storage_dir)\n",
    "            # index = \"Dummy\"\n",
    "            # add each index to index list\n",
    "            index_list.append(index)\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing subdirectory {relative_path}: {e}\")     \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Engine\n",
    "- in the previous code block, we converted all the files in Verbs example directory to index(Embeddings)\n",
    "- Now we can retrieve relevant block using the query engine. \n",
    "- A query engine in the context of information retrieval and language models is a component that processes queries by searching through a collection of data (like a set of documents or a database) and returning the most relevant information. \n",
    "\n",
    "### Retriever\n",
    "- Retrievers are responsible for fetching the most relevant context given a user query (or chat message).\n",
    "\n",
    "### RouterQueryEngine\n",
    "- Routers are modules that take in a user query and a set of \"choices\" (defined by metadata), and returns one or more selected choices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:24:41,641 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:24:41,643 [INFO] Selecting query engine 0: The Tutor training handbook may contain information on tools recommended for virtual meetings..\n",
      "2024-12-04 01:24:41,855 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:24:42,241 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoom or Google Meet are recommended for virtual meetings.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector, LLMMultiSelector\n",
    "from llama_index.core.selectors import (\n",
    "    PydanticMultiSelector,\n",
    "    PydanticSingleSelector,\n",
    ")\n",
    "def pretty_print_nodes_with_scores(nodes):\n",
    "    \n",
    "    for node_with_score in nodes:\n",
    "        node = node_with_score.node\n",
    "        score = node_with_score.score\n",
    "    \n",
    "        # Print relevant content (text) and metadata\n",
    "        print(\"Content:\", node.text)\n",
    "        print(\"Relevance Score:\", score)\n",
    "        print(\"Source:\", node.metadata.get(\"source\"))\n",
    "        print(\"Page:\", node.metadata.get(\"page\", \"N/A\"))\n",
    "        print(\"\\n---\\n\")\n",
    "    \n",
    "# 1. query_engine\n",
    "# Most likely, we would have multiple query engines\n",
    "chat_engines = []\n",
    "query_engine_tools = []\n",
    "for description, index in zip(description_list, index_list):\n",
    "    query_engine = index.as_query_engine(similarity_top_k=3)\n",
    "    query_engine_tools.append(\n",
    "        QueryEngineTool.from_defaults(query_engine=query_engine, \n",
    "                                      description=(f\"used to handle queries related to {description}.\")))\n",
    "    # chat_engines.append(index.as_chat_engine())\n",
    "\n",
    "# response = query_engine[2].query(\"How much does th tutor gets paid?\")\n",
    "# response = chat_engines[0].chat(\"How much does the tutor gets paid?\")\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=PydanticSingleSelector.from_defaults(),\n",
    "    query_engine_tools=query_engine_tools\n",
    ")\n",
    "response = query_engine.query(\"What tools are recommended for virtual meetings?\")\n",
    "print(str(response))\n",
    "# print(response)\n",
    "\n",
    "# 2. retriever\n",
    "# retriever = index_list[0].as_retriever()\n",
    "# nodes = retriever.retrieve(\"Who contributed to the handbook?\")\n",
    "\n",
    "# pretty_print_nodes_with_scores(nodes[:3])\n",
    "\n",
    "# 3. routerQueryEngine, if more than on query Engines are created then we can try this out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/zjh/micromamba/envs/rag_env/lib/python3.9/site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/zjh/micromamba/envs/rag_env/lib/python3.9/site-packages (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/zjh/micromamba/envs/rag_env/lib/python3.9/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zjh/micromamba/envs/rag_env/lib/python3.9/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zjh/micromamba/envs/rag_env/lib/python3.9/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zjh/micromamba/envs/rag_env/lib/python3.9/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/zjh/micromamba/envs/rag_env/lib/python3.9/site-packages (from beautifulsoup4) (2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    {\"Question\": \"How does Potencia facilitate communication between tutors and learners?\",\n",
    "     \"Answer\": \"Through scheduled meetings and shared platforms.\"},\n",
    "    {\"Question\": \"What tools are recommended for virtual meetings?\",\n",
    "     \"Answer\": \"Zoom, Google Meet, and consistent links.\"},\n",
    "    {\"Question\": \"How can tutors help learners overcome challenges with technology?\",\n",
    "     \"Answer\": \"Provide guidance and resources.\"},\n",
    "    {\"Question\": \"Why is consistency in meeting links important for online sessions?\",\n",
    "     \"Answer\": \"It reduces confusion and ensures reliability.\"},\n",
    "    {\"Question\": \"What questions should tutors ask themselves after each session for self-reflection?\",\n",
    "     \"Answer\": \"What went well, and what can I improve?\"},\n",
    "    {\"Question\": \"How can reflecting with learners after class improve teaching effectiveness?\",\n",
    "     \"Answer\": \"It provides feedback and builds rapport.\"},\n",
    "    {\"Question\": \"What factors should tutors consider when deciding on the next topic to teach?\",\n",
    "     \"Answer\": \"Learner goals and prior progress.\"},\n",
    "    {\"Question\": \"What is the recommended structure for a tutoring session?\",\n",
    "     \"Answer\": \"Warm-up, main activity, wrap-up.\"},\n",
    "    {\"Question\": \"How should a session be wrapped up effectively?\",\n",
    "     \"Answer\": \"Summarize and discuss next steps.\"},\n",
    "    {\"Question\": \"What is the tutoring session policy regarding session logging and cancellations?\",\n",
    "     \"Answer\": \"Log sessions and inform in advance about cancellations.\"},\n",
    "    {\"Question\": \"What informal assessments are recommended during a class session?\",\n",
    "     \"Answer\": \"Observation and on-the-spot questions.\"},\n",
    "    {\"Question\": \"How can quizzes and reading activities help assess a learner's knowledge?\",\n",
    "     \"Answer\": \"They evaluate comprehension and retention.\"},\n",
    "    {\"Question\": \"What forms of support does Potencia offer to tutors during the semester?\",\n",
    "     \"Answer\": \"Workshops, feedback sessions, and resources.\"}\n",
    "]\n",
    "\n",
    "# Create a filtered DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_file = \"Tutor_Questions_and_Answers.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does Potencia facilitate communication between tutors and learners?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:52:27,118 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:27,123 [INFO] Selecting query engine 0: Potencia facilitates communication between tutors and learners by providing guidance on Tutor training handbook, which can help tutors improve their communication skills..\n",
      "2024-12-04 01:52:27,517 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:28,386 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What tools are recommended for virtual meetings?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:52:28,848 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:28,851 [INFO] Selecting query engine 0: The Tutor training handbook may contain information on recommended tools for virtual meetings..\n",
      "2024-12-04 01:52:29,212 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:29,609 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can tutors help learners overcome challenges with technology?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:52:30,087 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:30,090 [INFO] Selecting query engine 0: The Tutor training handbook may provide guidance on how tutors can help learners overcome challenges with technology..\n",
      "2024-12-04 01:52:30,631 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:33,979 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is consistency in meeting links important for online sessions?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:52:34,465 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:34,467 [INFO] Selecting query engine 0: The choice related to Tutor training handbook may provide guidelines and best practices for maintaining consistency in meeting links for online sessions..\n",
      "2024-12-04 01:52:34,942 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:35,717 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What questions should tutors ask themselves after each session for self-reflection?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:52:36,227 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:36,229 [INFO] Selecting query engine 0: The Tutor training handbook may contain guidelines and suggestions for tutors on self-reflection questions after each session..\n",
      "2024-12-04 01:52:36,752 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:37,388 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can reflecting with learners after class improve teaching effectiveness?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:52:37,973 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:37,976 [INFO] Selecting query engine 0: Reflecting with learners after class can be a part of Tutor training handbook, which may provide guidance on effective reflection strategies for teachers to improve teaching effectiveness..\n",
      "2024-12-04 01:52:38,418 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:39,549 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What factors should tutors consider when deciding on the next topic to teach?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:52:39,989 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:39,992 [INFO] Selecting query engine 0: The Tutor training handbook may provide guidelines and considerations for tutors when deciding on the next topic to teach..\n",
      "2024-12-04 01:52:40,327 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:40,942 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the recommended structure for a tutoring session?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:52:41,757 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:41,760 [INFO] Selecting query engine 0: The Tutor training handbook would likely contain information on recommended structures for tutoring sessions..\n",
      "2024-12-04 01:52:42,227 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:43,598 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How should a session be wrapped up effectively?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:52:44,111 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:44,114 [INFO] Selecting query engine 2: Verbs are often used to indicate actions, which can be related to wrapping up a session effectively..\n",
      "2024-12-04 01:52:44,476 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:45,080 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the tutoring session policy regarding session logging and cancellations?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:52:45,652 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:45,654 [INFO] Selecting query engine 0: The Tutor training handbook is likely to contain policies and guidelines related to tutoring sessions, including session logging and cancellations..\n",
      "2024-12-04 01:52:46,137 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:46,732 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What informal assessments are recommended during a class session?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:52:47,188 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:47,191 [INFO] Selecting query engine 0: The Tutor training handbook may provide guidelines on informal assessments recommended during a class session..\n",
      "2024-12-04 01:52:47,393 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:47,829 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can quizzes and reading activities help assess a learner's knowledge?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:52:48,417 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:48,420 [INFO] Selecting query engine 0: The Tutor training handbook may provide guidance on how quizzes and reading activities can be used to assess a learner's knowledge..\n",
      "2024-12-04 01:52:48,724 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:49,729 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What forms of support does Potencia offer to tutors during the semester?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:52:50,361 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:50,364 [INFO] Selecting query engine 0: The choice related to handling queries related to Tutor training handbook seems most relevant to the question about the forms of support Potencia offers to tutors during the semester..\n",
      "2024-12-04 01:52:50,666 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-04 01:52:51,795 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Tutor_Questions_and_Answers.csv\")\n",
    "questions = df['Question']\n",
    "rag_responses = []\n",
    "for question in questions:\n",
    "    print(question)\n",
    "    rag_responses.append(query_engine.query(question))\n",
    "    \n",
    "df['RAG_Answer'] = rag_responses\n",
    "df.to_csv(output_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatEngine seems to perform much better than routerQuery engine\n",
    "Chat engine response: \n",
    "\n",
    "Here is a full lesson plan on verbs with specific practice examples:\n",
    "\n",
    "1. Introduction to Irregular Verb Tenses:\n",
    "   - Provide examples of irregular verbs in present and past tenses, such as \"am/was,\" \"write/wrote,\" \"draw/drew,\" \"do/did,\" \"make/made,\" \"meet/met,\" \"pay/paid,\" \"send/sent,\" \"sleep/slept,\" \"stand/stood,\" \"read/read,\" \"cut/cut,\" \"buy/bought,\" and \"see/saw.\"\n",
    "   \n",
    "2. Practice Activity:\n",
    "   - Engage students in creating sentences using both the present and past forms of irregular verbs. For example, transform \"I pay my bills every month\" into \"I paid the bills last month.\"\n",
    "   \n",
    "3. Future Tense:\n",
    "   - Introduce future tense examples like \"I am going to/I will\" for \"am/was,\" \"I will write\" for \"write/wrote,\" and so on. Have students practice creating sentences using the future tense forms of irregular verbs.\n",
    "   \n",
    "4. Conclusion and Homework:\n",
    "   - Review the irregular verb tenses covered in the lesson.\n",
    "   - Assign homework that involves creating sentences using both past and future tense forms of irregular verbs.\n",
    "\n",
    "Practice Examples:\n",
    "1. Write sentences using both the present and past forms of irregular verbs, such as \"I am a worker\" and \"I was a student.\"\n",
    "2. Create sentences with irregular verb tenses like \"I draw a flower\" and \"I drew a house.\"\n",
    "3. Practice using past tense words like \"Yesterday I made chicken\" and \"Yesterday, I stood in line at the store.\"\n",
    "4. Form sentences with irregular verbs in present and past forms, such as \"I send mail\" and \"I sent a letter.\"\n",
    "5. Utilize phrases with irregular verbs like \"I see you right now\" and \"I saw my mom yesterday.\"\n",
    "\n",
    "Feel free to incorporate these practice examples into your lesson plan to enhance student understanding of irregular verb tenses.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
